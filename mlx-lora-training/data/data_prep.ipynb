{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c336041",
   "metadata": {},
   "source": [
    "Reference: https://medium.com/rahasak/fine-tuning-llms-on-macos-using-mlx-and-run-with-ollama-182a20f1fd2c\n",
    "\n",
    "Download the dataset:\n",
    "`huggingface-cli download gretelai/synthetic_text_to_sql --repo-type dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe27e79",
   "metadata": {},
   "source": [
    "## Loading and preparing the data\n",
    "\n",
    "The existing data looks like this: \n",
    "```\n",
    "{\n",
    "  \"id\": 39325,\n",
    "  \"domain\": \"public health\",\n",
    "  \"domain_description\": \"Community health statistics, infectious disease tracking data, healthcare access metrics, and public health policy analysis.\",\n",
    "  \"sql_complexity\": \"aggregation\",\n",
    "  \"sql_complexity_description\": \"aggregation functions (COUNT, SUM, AVG, MIN, MAX, etc.), and HAVING clause\",\n",
    "  \"sql_task_type\": \"analytics and reporting\",\n",
    "  \"sql_task_type_description\": \"generating reports, dashboards, and analytical insights\",\n",
    "  \"sql_prompt\": \"What is the total number of hospital beds in each state?\",\n",
    "  \"sql_context\": \"CREATE TABLE Beds (State VARCHAR(50), Beds INT); INSERT INTO Beds (State, Beds) VALUES ('California', 100000), ('Texas', 85000), ('New York', 70000);\",\n",
    "  \"sql\": \"SELECT State, SUM(Beds) FROM Beds GROUP BY State;\",\n",
    "  \"sql_explanation\": \"This query calculates the total number of hospital beds in each state in the Beds table. It does this by using the SUM function on the Beds column and grouping the results by the State column.\"\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "We will combine `sql_prompt` and `sql_context` into a single prompt field and used the sql field as the completion. Additionally, MLX requires three sets of datasets: train, test, and valid. The data files should be in JSONL format. The final output files will have the following format:\n",
    "```\n",
    "{\n",
    "  \"prompt\":\"What is the total number of tickets sold for all football games? with given SQL schema CREATE TABLE tickets (ticket_id INT, game_id INT, region VARCHAR(50), quantity INT); INSERT INTO tickets (ticket_id, game_id, region, quantity) VALUES (1, 1, 'Midwest', 500); INSERT INTO tickets (ticket_id, game_id, region, quantity) VALUES (2, 2, 'Northeast', 700); CREATE TABLE games (game_id INT, sport VARCHAR(50)); INSERT INTO games (game_id, sport) VALUES (1, 'Football'); INSERT INTO games (game_id, sport) VALUES (2, 'Basketball');\",\n",
    "  \"completion\":\"SELECT SUM(quantity) FROM tickets INNER JOIN games ON tickets.game_id = games.game_id WHERE sport = 'Football';\"\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61837117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deyarchit/Projects/ai/ml-training/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0  What is the total volume of timber sold by eac...   \n",
      "1  List all the unique equipment types and their ...   \n",
      "2  How many marine species are found in the South...   \n",
      "3  What is the total trade value and average pric...   \n",
      "4  Find the energy efficiency upgrades with the h...   \n",
      "5  What is the total spending on humanitarian ass...   \n",
      "6  What is the average water temperature for each...   \n",
      "7  Delete a program's outcome data with given SQL...   \n",
      "8  Find the total fare collected from passengers ...   \n",
      "9  What is the average property size in inclusive...   \n",
      "\n",
      "                                          completion  \n",
      "0  SELECT salesperson_id, name, SUM(volume) as to...  \n",
      "1  SELECT equipment_type, SUM(maintenance_frequen...  \n",
      "2  SELECT COUNT(*) FROM marine_species WHERE loca...  \n",
      "3  SELECT trader_id, stock, SUM(price * quantity)...  \n",
      "4  SELECT type, cost FROM (SELECT type, cost, ROW...  \n",
      "5  SELECT SUM(spending) FROM defense.eu_humanitar...  \n",
      "6  SELECT SpeciesName, AVG(WaterTemp) as AvgTemp ...  \n",
      "7  DELETE FROM Program_Outcomes WHERE program_id ...  \n",
      "8  SELECT SUM(fare) FROM bus_routes WHERE route_n...  \n",
      "9  SELECT AVG(Property_Size) FROM Inclusive_Housi...  \n",
      "                                              prompt  \\\n",
      "0  What is the average explainability score of cr...   \n",
      "1  Delete all records of rural infrastructure pro...   \n",
      "2  How many accidents have been recorded for Spac...   \n",
      "3  What is the maximum quantity of seafood sold i...   \n",
      "4  What is the total budget for movies released b...   \n",
      "5  Add a new attorney named 'Oliver Martinez' wit...   \n",
      "6  Identify the top 2 plants with the highest CO2...   \n",
      "7  What is the total cost of all climate communic...   \n",
      "8  List all marine species with their conservatio...   \n",
      "9  What is the average number of publications per...   \n",
      "\n",
      "                                          completion  \n",
      "0  SELECT AVG(explainability_score) FROM creative...  \n",
      "1  DELETE FROM rural_infrastructure WHERE country...  \n",
      "2  SELECT launch_provider, COUNT(*) FROM Accident...  \n",
      "3                   SELECT MAX(quantity) FROM sales;  \n",
      "4  SELECT SUM(budget) FROM Movies_Release_Year WH...  \n",
      "5  INSERT INTO attorneys (attorney_name, attorney...  \n",
      "6  SELECT plant_name, SUM(co2_emission_per_ton_pr...  \n",
      "7  SELECT SUM(total_cost) FROM climate_communicat...  \n",
      "8  SELECT name, conservation_status FROM marine_s...  \n",
      "9  SELECT organization, AVG(publications) as avg_...  \n",
      "                                                 prompt  \\\n",
      "3900  What is the total number of tickets sold for a...   \n",
      "3901  What is the total revenue for the soccer team ...   \n",
      "3902  Identify the number of security incidents that...   \n",
      "3903  Identify the top 5 threat intelligence sources...   \n",
      "3904  What are the collective bargaining agreements ...   \n",
      "3905  How many vessels arrived in Brazil in July 202...   \n",
      "3906  What was the maximum cargo weight for vessels ...   \n",
      "3907  Find the top 3 regions with the highest water ...   \n",
      "3908  List all water sources located in California, ...   \n",
      "3909  What is the average bias score for each attrib...   \n",
      "\n",
      "                                             completion  \n",
      "3900  SELECT SUM(quantity) FROM tickets INNER JOIN g...  \n",
      "3901  SELECT SUM(tickets.quantity * games.price) FRO...  \n",
      "3902  SELECT COUNT(*) FROM incidents WHERE incident_...  \n",
      "3903  SELECT source, SUM(incident_count) as total_in...  \n",
      "3904  SELECT UnionName, ExpirationDate FROM CBAs WHE...  \n",
      "3905  SELECT COUNT(*) FROM vessel_performance WHERE ...  \n",
      "3906  SELECT MAX(cargo_weight) FROM vessels WHERE po...  \n",
      "3907  SELECT region, SUM(efforts) AS total_efforts F...  \n",
      "3908  SELECT * FROM water_sources WHERE location LIK...  \n",
      "3909  SELECT algorithm, attribute, AVG(bias_score) a...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'synthetic_text_to_sql_train.snappy.parquet', 'test': 'synthetic_text_to_sql_test.snappy.parquet'}\n",
    "\n",
    "def prepare_train():\n",
    "    df = pd.read_parquet(\"hf://datasets/gretelai/synthetic_text_to_sql/\" + splits[\"train\"])\n",
    "\n",
    "    df['prompt'] = df['sql_prompt'] + \" with given SQL schema \" + df['sql_context']\n",
    "    df.rename(columns={'sql': 'completion'}, inplace=True)\n",
    "    df = df[['prompt', 'completion']]\n",
    "\n",
    "    print(df.head(10))\n",
    "\n",
    "    # Convert the DataFrame to a JSON format, with each record on a new line\n",
    "    # save as .jsonl\n",
    "    df.to_json('train.jsonl', orient='records', lines=True)\n",
    "\n",
    "\n",
    "def prepare_test_valid():\n",
    "    df = pd.read_parquet(\"hf://datasets/gretelai/synthetic_text_to_sql/\" + splits[\"test\"])\n",
    "\n",
    "    df['prompt'] = df['sql_prompt'] + \" with given SQL schema \" + df['sql_context']\n",
    "    df.rename(columns={'sql': 'completion'}, inplace=True)\n",
    "    df = df[['prompt', 'completion']]\n",
    "\n",
    "    # Calculate split index for two-thirds\n",
    "    split_index = int(len(df) * 2 / 3)\n",
    "\n",
    "    # Split the DataFrame into two parts\n",
    "    test_df = df[:split_index]\n",
    "    valid_df = df[split_index:]\n",
    "\n",
    "    print(test_df.head(10))\n",
    "    print(valid_df.head(10))\n",
    "\n",
    "    # Save the subsets to their respective JSONL files\n",
    "    test_df.to_json('test.jsonl', orient='records', lines=True)\n",
    "    valid_df.to_json('valid.jsonl', orient='records', lines=True)\n",
    "\n",
    "\n",
    "prepare_train()\n",
    "prepare_test_valid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
