{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbc51c8",
   "metadata": {},
   "source": [
    "## Fine tune / Train LLM\n",
    "\n",
    "### Downloading and inspecting the model\n",
    "\n",
    "```\n",
    "▶ huggingface-cli download mlx-community/Qwen3-1.7B-4bit\n",
    "\n",
    "▶ ls ~/.cache/huggingface/hub/models--mlx-community--Qwen3-1.7B-4bit  \n",
    "blobs     refs      snapshots\n",
    "\n",
    "# Note: The path where hugging face cache and mlx models are stored is the same\n",
    "▶ huggingface-cli scan-cache\n",
    "REPO ID                                     REPO TYPE SIZE ON DISK NB FILES LAST_ACCESSED  LAST_MODIFIED  REFS LOCAL PATH\n",
    "------------------------------------------- --------- ------------ -------- -------------- -------------- ---- --------------------------------------------------------------------------------------------\n",
    "gretelai/synthetic_text_to_sql              dataset          34.3M        8 48 minutes ago 48 minutes ago main /Users/deyarchit/.cache/huggingface/hub/datasets--gretelai--synthetic_text_to_sql\n",
    "mistralai/Mistral-7B-Instruct-v0.3          model            29.0G       15 12 minutes ago 3 minutes ago  main /Users/deyarchit/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.3\n",
    "mlx-community/Mistral-7B-Instruct-v0.3-4bit model             4.1G        7 4 weeks ago    4 weeks ago    main /Users/deyarchit/.cache/huggingface/hub/models--mlx-community--Mistral-7B-Instruct-v0.3-4bit\n",
    "mlx-community/gemma-3-4b-it-4bit            model             3.4G       12 4 weeks ago    4 weeks ago    main /Users/deyarchit/.cache/huggingface/hub/models--mlx-community--gemma-3-4b-it-4bit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e5e645",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Note: \n",
    "\n",
    "```\n",
    "python -m mlx_lm lora \\\n",
    "  --model mlx-community/Qwen3-1.7B-4bit \\\n",
    "  --fine-tune-type lora \\\n",
    "  --data data \\\n",
    "  --train \\\n",
    "  --batch-size 4\\\n",
    "  --num-layers 16\\\n",
    "  --iters 1000\n",
    "\n",
    "Loading pretrained model\n",
    "Fetching 9 files: 100%|████████████████████████████████| 9/9 [00:00<00:00, 21732.15it/s]\n",
    "Loading datasets\n",
    "Training\n",
    "Trainable parameters: 0.053% (0.918M/1720.575M)\n",
    "Starting training..., iters: 1000\n",
    "Iter 1: Val loss 2.567, Val took 31.900s\n",
    "Iter 10: Train loss 2.293, Learning Rate 1.000e-05, It/sec 0.358, Tokens/sec 226.100, Trained Tokens 6308, Peak mem 4.906 GB\n",
    ".\n",
    ".\n",
    ".\n",
    "Iter 1000: Val loss 0.689, Val took 35.469s\n",
    "Iter 1000: Train loss 0.670, Learning Rate 1.000e-05, It/sec 0.290, Tokens/sec 190.825, Trained Tokens 637302, Peak mem 8.651 GB\n",
    "Iter 1000: Saved adapter weights to adapters/adapters.safetensors and adapters/0001000_adapters.safetensors.\n",
    "Saved final weights to adapters/adapters.safetensors.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e468a",
   "metadata": {},
   "source": [
    "## Evaluating LLM\n",
    "\n",
    "### Testing the fine-tuned LLM using test data:\n",
    "```\n",
    "▶ python -m mlx_lm lora \\\n",
    "  --model mlx-community/Qwen3-1.7B-4bit \\\n",
    "  --adapter-path adapters \\\n",
    "  --data data \\\n",
    "  --test\n",
    "Loading pretrained model\n",
    "Fetching 9 files: 100%|███████████████████████████████| 9/9 [00:00<00:00, 140329.87it/s]\n",
    "Loading datasets\n",
    "Testing\n",
    "Test loss 0.657, Test ppl 1.929.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Testing with this data point from the test set:\n",
    "\n",
    "```\n",
    "{\"prompt\":\"What is the average explainability score of creative AI applications in 'Europe' and 'North America' in the 'creative_ai' table? with given SQL schema CREATE TABLE creative_ai (application_id INT, name TEXT, region TEXT, explainability_score FLOAT); INSERT INTO creative_ai (application_id, name, region, explainability_score) VALUES (1, 'ApplicationX', 'Europe', 0.87), (2, 'ApplicationY', 'North America', 0.91), (3, 'ApplicationZ', 'Europe', 0.84), (4, 'ApplicationAA', 'North America', 0.93), (5, 'ApplicationAB', 'Europe', 0.89);\",\"completion\":\"SELECT AVG(explainability_score) FROM creative_ai WHERE region IN ('Europe', 'North America');\"}\n",
    "```\n",
    "\n",
    "#### Prompting the original LLM:\n",
    "```\n",
    "▶ mlx_lm.generate \\\n",
    "     --model mlx-community/Qwen3-1.7B-4bit \\\n",
    "     --max-tokens 2000 \\\n",
    "     --prompt \"Write a SQL query to find the average explainability score of creative AI applications in 'Europe' and 'North America' in the 'creative_ai' table? with given SQL schema CREATE TABLE creative_ai (application_id INT, name TEXT, region TEXT, explainability_score FLOAT); INSERT INTO creative_ai (application_id, name, region, explainability_score) VALUES (1, 'ApplicationX', 'Europe', 0.87), (2, 'ApplicationY', 'North America', 0.91), (3, 'ApplicationZ', 'Europe', 0.84), (4, 'ApplicationAA', 'North America', 0.93), (5, 'ApplicationAB', 'Europe', 0.89);\"\n",
    "Fetching 9 files: 100%|█████████████████████████████████| 9/9 [00:00<00:00, 80487.71it/s]\n",
    "==========\n",
    "To calculate the average explainability score for **creative AI applications in Europe** and **North America**, we can use a SQL query that groups the data by region and computes the average for each group.\n",
    "\n",
    "SQL Query:\n",
    "\n",
    "SELECT region, AVG(explainability_score) AS average_score\n",
    "FROM creative_ai\n",
    "GROUP BY region;\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Explanation:\n",
    "\n",
    "- **`SELECT region, AVG(explainability_score) AS average_score`**  \n",
    "  This selects the region and the average explainability score for each region.\n",
    "\n",
    "- **`FROM creative_ai`**  \n",
    "  Specifies the table from which to retrieve data.\n",
    "\n",
    "- **`GROUP BY region`**  \n",
    "  Groups the rows by region, ensuring that the average is calculated for each region separately.\n",
    "\n",
    "---\n",
    "\n",
    "Output:\n",
    "\n",
    "The query will return two rows:\n",
    "\n",
    "| region | average_score |\n",
    "|--------|---------------|\n",
    "| Europe | 0.8667       |\n",
    "| North America | 0.92     |\n",
    "\n",
    "---\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The `AVG(explainability_score)` function calculates the mean score for each region.\n",
    "- The query assumes that the `region` column contains only values of `'Europe'` and `'North America'`.\n",
    "\n",
    "Prompt: 163 tokens, 587.505 tokens-per-sec\n",
    "Generation: 1751 tokens, 74.075 tokens-per-sec\n",
    "Peak memory: 1.351 GB\n",
    "```\n",
    "\n",
    "### Prompting the original LLM with trained adapters:\n",
    "\n",
    "```\n",
    "▶ mlx_lm.generate \\\n",
    "     --model mlx-community/Qwen3-1.7B-4bit \\\n",
    "     --max-tokens 2000 \\\n",
    "     --adapter-path adapters \\\n",
    "     --prompt \"Write a SQL query to find the average explainability score of creative AI applications in 'Europe' and 'North America' in the 'creative_ai' table? with given SQL schema CREATE TABLE creative_ai (application_id INT, name TEXT, region TEXT, explainability_score FLOAT); INSERT INTO creative_ai (application_id, name, region, explainability_score) VALUES (1, 'ApplicationX', 'Europe', 0.87), (2, 'ApplicationY', 'North America', 0.91), (3, 'ApplicationZ', 'Europe', 0.84), (4, 'ApplicationAA', 'North America', 0.93), (5, 'ApplicationAB', 'Europe', 0.89);\"\n",
    "Fetching 9 files: 100%|████████████████████████████████| 9/9 [00:00<00:00, 155986.51it/s]\n",
    "\n",
    "\n",
    "SELECT AVG(explainability_score) FROM creative_ai WHERE region IN ('Europe', 'North America');\n",
    "\n",
    "Prompt: 163 tokens, 578.914 tokens-per-sec\n",
    "Generation: 25 tokens, 80.978 tokens-per-sec\n",
    "Peak memory: 1.295 GB\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
